{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python364jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.6.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BDCC HW: Task 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Task: Implement a MapReduce job that creates a list of followers for each user in the dataset.\n",
    "\n",
    "Example: the list of followers of user 534 is: [2, 16, 37, 73, 156, 210, 308, 347, 446, 455, 487, 519]."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting src/task1.py\n"
     ]
    }
   ],
   "source": [
    "%%file src/task1.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "\n",
    "# Implement a MapReduce job that creates a list of followers for each user in the dataset.\n",
    "class Followers(MRJob):\n",
    "\n",
    "    # Arg 1: self: the class itself (this)\n",
    "    # Arg 2: Input key to the map function\n",
    "    # Arg 3: Input value to the map function (one line from the input file)\n",
    "    def mapper(self, _, line):\n",
    "\n",
    "        # TODO ordering of keys\n",
    "\n",
    "        # yield (follower, followee) pair\n",
    "        (follower, followee) = line.split()\n",
    "        yield(int(followee), follower)\n",
    "\n",
    "\n",
    "    # Arg 1: self: the class itself (this)\n",
    "    # Arg 2: Input key to the reduce function (here: the key that was emitted by the mapper)\n",
    "    # Arg 3: Input value to the reduce function (here: a generator object; something like a\n",
    "    # sorted list of ALL values associated with the same key)\n",
    "    def reducer(self, followee, followers):\n",
    "        followers_list = [follower for follower in followers]\n",
    "        yield(followee, sorted(followers_list))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Followers.run()\n"
   ]
  },
  {
   "source": [
    "### Run in Standalone Mode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /var/folders/f7/py_w9f_n5fz4vg7_hty30b0m0000gn/T/task1.sheenafernandez.20210515.182050.634755\n",
      "Running step 1 of 1...\n",
      "\n",
      "Error while reading from /var/folders/f7/py_w9f_n5fz4vg7_hty30b0m0000gn/T/task1.sheenafernandez.20210515.182050.634755/step/000/mapper/00000/input:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"src/task1.py\", line 32, in <module>\n",
      "    Followers.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 616, in run\n",
      "    cls().execute()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 687, in execute\n",
      "    self.run_job()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 636, in run_job\n",
      "    runner.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/runner.py\", line 503, in run\n",
      "    self._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/sim.py\", line 161, in _run\n",
      "    self._run_step(step, step_num)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/sim.py\", line 170, in _run_step\n",
      "    self._run_streaming_step(step, step_num)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/sim.py\", line 181, in _run_streaming_step\n",
      "    self._run_mappers_and_combiners(step_num, map_splits)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/sim.py\", line 222, in _run_mappers_and_combiners\n",
      "    for task_num, map_split in enumerate(map_splits)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/sim.py\", line 130, in _run_multiple\n",
      "    func()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/sim.py\", line 724, in _run_mapper_and_combiner\n",
      "    run_mapper()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/sim.py\", line 747, in _run_task\n",
      "    stdin, stdout, stderr, wd, env)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/inline.py\", line 133, in invoke_task\n",
      "    task.execute()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 675, in execute\n",
      "    self.run_mapper(self.options.step_num)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 760, in run_mapper\n",
      "    for k, v in self.map_pairs(read_lines(), step_num=step_num):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 830, in map_pairs\n",
      "    for k, v in mapper(key, value) or ():\n",
      "  File \"src/task1.py\", line 18, in mapper\n",
      "    print(type(followee))\n",
      "TypeError: a bytes-like object is required, not 'str'\n"
     ]
    }
   ],
   "source": [
    "!python3 src/task1.py data/graph.txt"
   ]
  },
  {
   "source": [
    "### Run in the Hadoop cluster in a fully/pseudo distributed mode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No configs found; falling back on auto-configuration\nNo configs specified for hadoop runner\nLooking for hadoop binary in $PATH...\nFalling back to 'hadoop'\nTraceback (most recent call last):\n  File \"src/task1.py\", line 31, in <module>\n    Followers.run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 616, in run\n    cls().execute()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 687, in execute\n    self.run_job()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/job.py\", line 636, in run_job\n    runner.run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/runner.py\", line 503, in run\n    self._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/hadoop.py\", line 325, in _run\n    self._find_binaries_and_jars()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/hadoop.py\", line 339, in _find_binaries_and_jars\n    self.get_hadoop_version()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/hadoop.py\", line 210, in get_hadoop_version\n    return self.fs.hadoop.get_hadoop_version()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/fs/hadoop.py\", line 128, in get_hadoop_version\n    stdout = self.invoke_hadoop(['version'], return_stdout=True)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mrjob/fs/hadoop.py\", line 160, in invoke_hadoop\n    proc = Popen(args, stdout=PIPE, stderr=PIPE)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\", line 709, in __init__\n    restore_signals, start_new_session)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\", line 1344, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'hadoop': 'hadoop'\n"
     ]
    }
   ],
   "source": [
    "!python3 src/task1.py -r hadoop data/graph.txt -o task1_output"
   ]
  },
  {
   "source": [
    "### Copy the output from HDFS to local file system."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyToLocal task1_output /home/bdccuser/bdcc-assignment1/output/task1"
   ]
  }
 ]
}